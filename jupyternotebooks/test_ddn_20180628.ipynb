{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from graphviz import Digraph\n",
    "from graphviz import Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BrologAnalyzer:\n",
    "\n",
    "    def __init__(self, directory, target):\n",
    "        self._bro_dir = directory\n",
    "        self._bro_target = target\n",
    "        \n",
    "    def _get_entries(self, fname):\n",
    "        with open(self._bro_dir + fname) as f:\n",
    "            entries = f.readlines()\n",
    "        entries = [x.strip() for x in entries]\n",
    "        #print(len(entries))\n",
    "        return entries\n",
    "    \n",
    "    def _get_other_topics(self):\n",
    "        fnames = [f for f in listdir(self._bro_dir) if isfile(join(self._bro_dir, f))]\n",
    "        fnames.remove(self._bro_target)\n",
    "        if self._bro_target == \"conn.log\":\n",
    "            try:\n",
    "                fnames.remove(\"tds.log\")\n",
    "            except:\n",
    "                pass\n",
    "        #print(fnames)\n",
    "        return fnames\n",
    "    \n",
    "    def _get_target_tscut(self, target_log_str, tscut):\n",
    "        res = []\n",
    "        tstarget = json.loads(target_log_str)['ts']\n",
    "        orig_h_target = json.loads(target_log_str)['id.orig_h']\n",
    "        orig_p_target = json.loads(target_log_str)['id.orig_p']\n",
    "        resp_h_target = json.loads(target_log_str)['id.resp_h']\n",
    "        resp_p_target = json.loads(target_log_str)['id.resp_p']\n",
    "        \n",
    "        #print(tstarget)\n",
    "        #print(orig_h_target, orig_p_target)\n",
    "        #print(resp_h_target, resp_p_target)\n",
    "\n",
    "        fnames = self._get_other_topics()\n",
    "        for fname in fnames:\n",
    "            entries = self._get_entries(fname)\n",
    "            #print(fname)\n",
    "            #print(len(entries))\n",
    "            for entry in entries:\n",
    "                try:\n",
    "                    entry_dict = json.loads(entry)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    tsentry = entry_dict['ts']\n",
    "                    orig_h_entry = json.loads(entry)['id.orig_h']\n",
    "                    orig_p_entry = json.loads(entry)['id.orig_p']\n",
    "                    resp_h_entry = json.loads(entry)['id.resp_h']\n",
    "                    resp_p_entry = json.loads(entry)['id.resp_p']\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                #if_related = (orig_h_entry==resp_h_target and orig_p_entry==resp_p_target) or (resp_h_entry==resp_h_target and resp_p_entry==resp_p_target)\n",
    "                diff = tsentry - tstarget\n",
    "                if diff > 0 and diff < tscut:\n",
    "                    #print(entry)\n",
    "                    res.append(entry)\n",
    "        return res\n",
    "    \n",
    "    def _get_graph(self, outdir, outfname, target_log_str, res_log_str_list):       \n",
    "        dot = Digraph(comment='test graph')\n",
    "        orig_h_target = json.loads(target_log_str)['id.orig_h']\n",
    "        orig_p_target = json.loads(target_log_str)['id.orig_p']\n",
    "        resp_h_target = json.loads(target_log_str)['id.resp_h']\n",
    "        resp_p_target = json.loads(target_log_str)['id.resp_p']\n",
    "        #print(type(orig_h_target))\n",
    "        #print(type(orig_p_target))\n",
    "        dot.node(orig_h_target, str(orig_h_target), color='red')\n",
    "        dot.node(resp_h_target, str(resp_h_target), color='red')\n",
    "        dot.edge(orig_h_target, resp_h_target, constraint='false', headlabel = str(orig_p_target), taillabel = str(resp_p_target), labelfontsize=\"8\", len=\"3.0\", color='red')\n",
    "        \n",
    "        for res_log_str in res_log_str_list:\n",
    "            orig_h_res = json.loads(res_log_str)['id.orig_h']\n",
    "            orig_p_res = json.loads(res_log_str)['id.orig_p']\n",
    "            resp_h_res = json.loads(res_log_str)['id.resp_h']\n",
    "            resp_p_res = json.loads(res_log_str)['id.resp_p']\n",
    "            dot.node(orig_h_res, str(orig_h_res))\n",
    "            dot.node(resp_h_res, str(resp_h_res))\n",
    "            dot.edge(orig_h_res, resp_h_res, constraint='false', headlabel = str(orig_p_res), taillabel = str(resp_p_res), labelfontsize=\"8\", len=\"3.0\", color='blue')\n",
    "        \n",
    "        try:\n",
    "            dot.render(outdir + '/' + outfname, view=False)  \n",
    "            return dot\n",
    "        except:\n",
    "            print(\"render failed!\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#myBrologAnalyzer = BrologAnalyzer(\"../data/brologs/03-28/\", \"tds_sqlbatch.log\")\n",
    "myBrologAnalyzer = BrologAnalyzer(\"../data/brologs/03-28/\", \"conn.log\")\n",
    "\n",
    "#myBrologAnalyzer = BrologAnalyzer(\"../data/brologs/03-22-13/\", \"tds_sqlbatch.log\")\n",
    "#targets = myBrologAnalyzer._get_entries(myBrologAnalyzer._bro_target)\n",
    "#myBrologAnalyzer._get_entries(\"conn.log\")\n",
    "\n",
    "#for thistarget in targets:\n",
    "#    if json.loads(thistarget)['id.resp_p'] == 1433:\n",
    "        #print(thistarget)\n",
    "#        test_res = myBrologAnalyzer._get_target_tscut(thistarget, 1)\n",
    "        \n",
    "#myBrologAnalyzer._get_other_topics()\n",
    "#03-22-13\n",
    "#test_target_log_str = '{\"ts\":1521699403.756506,\"uid\":\"C4Y1Xt1AqErW7gd1Kl\",\"id.orig_h\":\"192.168.3.61\",\"id.orig_p\":61617,\"id.resp_h\":\"172.16.1.58\",\"id.resp_p\":1433,\"sqlbatch\":\"\\\\u0016\\\\u0012\\\\u0002\\\\u00fc\\\\u0088u\\\\u0001select * from EXT_ORDER_NEW\\\\u000d\\\\u000aWhere UPDSTATUS IS NUL\"}'\n",
    "#03-28\n",
    "#test_target_log_str = '{\"ts\":1522298700.448996,\"uid\":\"CJt0DqsKHR4gQU03e\",\"id.orig_h\":\"172.16.3.106\",\"id.orig_p\":51300,\"id.resp_h\":\"172.16.3.104\",\"id.resp_p\":1433,\"sqlbatch\":\"\\\\u0016\\\\u0012\\\\u0002\\\\u0001SELECT TOP 1 * FROM [INTClient\"}'\n",
    "#test_target_log_str = '{\"ts\":1522298698.48293,\"uid\":\"CP32sg2ZDTgkC1V2c4\",\"id.orig_h\":\"172.16.3.106\",\"id.orig_p\":51705,\"id.resp_h\":\"172.16.3.123\",\"id.resp_p\":1433,\"proto\":\"tcp\",\"duration\":99.982921,\"orig_bytes\":1,\"resp_bytes\":0,\"conn_state\":\"SF\",\"missed_bytes\":0,\"history\":\"DadAFf\",\"orig_pkts\":10,\"orig_ip_bytes\":452,\"resp_pkts\":10,\"resp_ip_bytes\":452,\"tunnel_parents\":[]}'\n",
    "#test_res_log_str_list = myBrologAnalyzer._get_target_tscut(test_target_log_str, 1)\n",
    "#print(len(test_res_log_str_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#res_dot = myBrologAnalyzer._get_graph(\"graph_plots\", \"test_graph.gv\", test_target_log_str, test_res_log_str_list)\n",
    "#print(str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_labels = set([9,10,12,19,26,42,55,523])\n",
    "#good_labels = set()\n",
    "def _gen_graph_batch(thisBrologAnalyzer, tscut, port_target):\n",
    "    i = 0\n",
    "    outdir = \"graph_tscut_\" + str(tscut)\n",
    "    raw_targets = thisBrologAnalyzer._get_entries(thisBrologAnalyzer._bro_target)\n",
    "    targets = [x for x in raw_targets if ('\"id.resp_p\":' + str(port_target)) in x]\n",
    "    print(len(targets))\n",
    "    for thistarget in targets:\n",
    "        i += 1\n",
    "        print(\"processing event \" + str(i) + \"...\")\n",
    "        if i in good_labels:\n",
    "            outfname = \"graph_\" + str(i) + \"_\" + str(port_target) + \".gv\"\n",
    "            thisres_list = thisBrologAnalyzer._get_target_tscut(thistarget, tscut)\n",
    "            thisBrologAnalyzer._get_graph(outdir, outfname, thistarget, thisres_list)\n",
    "            with open(outdir + '/' + outfname + '.txt', 'a') as the_file:\n",
    "                the_file.write(\"Tagert: \\n\")\n",
    "                the_file.write(thistarget)\n",
    "                the_file.write(\"\\n\")\n",
    "                the_file.write(\"\\n\")\n",
    "                the_file.write(\"Ohters: \\n\")\n",
    "                for x in thisres_list:\n",
    "                    the_file.write(x)\n",
    "                    the_file.write(\"\\n\")\n",
    "                the_file.close()\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "#_gen_graph_batch(myBrologAnalyzer, 1, 1433)\n",
    "#_gen_graph_batch(myBrologAnalyzer, 5, 1433)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _ddn_json_reformat_js(path, fname):\n",
    "    nodes_list = []\n",
    "    edges_list = []\n",
    "    with open(path + fname) as f:\n",
    "        data = json.load(f)\n",
    "        nodes = json.loads(data['nodes'])\n",
    "        nodes_list = []\n",
    "        #em... let's try to add some icons...\n",
    "        for n in nodes[\"iid\"].keys():\n",
    "            nodes_list.append({\"name\": nodes[\"node_id\"][n], \"group\": nodes[\"type\"][n]})\n",
    "        \n",
    "        #\"iid\"\n",
    "        #nodes[\"iid\"]\n",
    "        inv_node_iid_map = {v: k for k, v in nodes[\"iid\"].items()}\n",
    "        #print(inv_node_iid_map)\n",
    "        \n",
    "        edges = json.loads(data['edges'])\n",
    "        for e in edges[\"ddn_id\"].keys():\n",
    "            thislabel = \"_\".join([edges[\"proto\"][e], edges[\"port\"][e], str(edges[\"total_bytes\"][e])])\n",
    "            #print(inv_node_id_map[edges[\"iid_from\"][e]])\n",
    "            #print(edges[\"iid_to\"][e])\n",
    "            iid_from = edges[\"iid_from\"][e]\n",
    "            iid_to = edges[\"iid_to\"][e]\n",
    "            if iid_from in inv_node_iid_map.keys() and iid_to in inv_node_iid_map.keys():\n",
    "                #print(iid_from, iid_to)\n",
    "                edges_list.append({\"source\": int(inv_node_iid_map[iid_from]), \"target\": int(inv_node_iid_map[iid_to]), \"label\": thislabel})\n",
    "    #return nodes_list\n",
    "    #return edges_list\n",
    "    ddn_d3_res = {\"nodes\": nodes_list, \"links\": edges_list}\n",
    "    \n",
    "    with open(\"../d3js/ddn/\" + \"d3js_\" + fname, 'w') as fp:\n",
    "        json.dump(ddn_d3_res, fp)\n",
    "    return ddn_d3_res\n",
    "\n",
    "ddn_dict_d3js = _ddn_json_reformat_js(\"../data/ddn/\", \"ddn_hr.json\")\n",
    "ddn_dict_d3js = _ddn_json_reformat_js(\"../data/ddn/\", \"ddn_pii.json\")\n",
    "#print(type(ddn_dict_d3js))\n",
    "#print(ddn_dict_d3js)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New section for ddn api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import copy\n",
    "from functools import reduce\n",
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>applications</th>\n",
       "      <th>datastores</th>\n",
       "      <th>ddnId</th>\n",
       "      <th>ddnName</th>\n",
       "      <th>users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'uri': 'youtube.com', 'appName': 'youtube.co...</td>\n",
       "      <td>[{'nodeType': 'FILE', 'nodeId': '192.168.7.110...</td>\n",
       "      <td>5a105e8b9d40e1329780d62ea2265d8a</td>\n",
       "      <td>test1</td>\n",
       "      <td>[{'ip': '192.168.7.188', 'lastSeenTime': '1', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'uri': 'youtube.com', 'appName': 'youtube.co...</td>\n",
       "      <td>[{'nodeType': 'FILE', 'nodeId': '192.168.7.110...</td>\n",
       "      <td>ad0234829205b9033196ba818f7a872b</td>\n",
       "      <td>test2</td>\n",
       "      <td>[{'ip': '192.168.7.188', 'lastSeenTime': '1', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        applications  \\\n",
       "0  [{'uri': 'youtube.com', 'appName': 'youtube.co...   \n",
       "1  [{'uri': 'youtube.com', 'appName': 'youtube.co...   \n",
       "\n",
       "                                          datastores  \\\n",
       "0  [{'nodeType': 'FILE', 'nodeId': '192.168.7.110...   \n",
       "1  [{'nodeType': 'FILE', 'nodeId': '192.168.7.110...   \n",
       "\n",
       "                              ddnId ddnName  \\\n",
       "0  5a105e8b9d40e1329780d62ea2265d8a   test1   \n",
       "1  ad0234829205b9033196ba818f7a872b   test2   \n",
       "\n",
       "                                               users  \n",
       "0  [{'ip': '192.168.7.188', 'lastSeenTime': '1', ...  \n",
       "1  [{'ip': '192.168.7.188', 'lastSeenTime': '1', ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_ddn_json(fs_name):\n",
    "    with open(fs_name) as f:\n",
    "        #ddn_raw = f.read()\n",
    "        ddn_raw = ast.literal_eval(f.read())\n",
    "        #print(type(ddn_raw))\n",
    "        #print(ddn_raw)\n",
    "        ddn_df = pd.DataFrame(ddn_raw)\n",
    "        return ddn_df\n",
    "\n",
    "test_ddn_df = load_ddn_json(\"data/ddn_test.json\")\n",
    "test_ddn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_explode(df, column_to_explode):\n",
    "    \"\"\"\n",
    "    Similar to Hive's EXPLODE function, take a column with iterable elements, and flatten the iterable to one element \n",
    "    per observation in the output table\n",
    "\n",
    "    :param df: A dataframe to explod\n",
    "    :type df: pandas.DataFrame\n",
    "    :param column_to_explode: \n",
    "    :type column_to_explode: str\n",
    "    :return: An exploded data frame\n",
    "    :rtype: pandas.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a list of new observations\n",
    "    new_observations = list()\n",
    "\n",
    "    # Iterate through existing observations\n",
    "    for row in df.to_dict(orient='records'):\n",
    "\n",
    "        # Take out the exploding iterable\n",
    "        explode_values = row[column_to_explode]\n",
    "        del row[column_to_explode]\n",
    "\n",
    "        # Create a new observation for every entry in the exploding iterable & add all of the other columns\n",
    "        for explode_value in explode_values:\n",
    "\n",
    "            # Deep copy existing observation\n",
    "            new_observation = copy.deepcopy(row)\n",
    "\n",
    "            # Add one (newly flattened) value from exploding iterable\n",
    "            new_observation[column_to_explode] = explode_value\n",
    "\n",
    "            # Add to the list of new observations\n",
    "            new_observations.append(new_observation)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    return_df = pd.DataFrame(new_observations)\n",
    "\n",
    "    # Return\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ddn_id': '5a105e8b9d40e1329780d62ea2265d8a', 'ddn_name': 'test1', 'node_type': 'users', 'node_id': '192.168.7.188', 'node_attr': {'ip': '192.168.7.188', 'lastSeenTime': '1', 'edges': [{'idFrom': '192.168.7.188', 'idTo': 'youtube.com/12.3.4.52131'}], 'attributes': [{'attrName': 'user_access', 'attrType': 'ACCESS_GROUP', 'attrValue': 'contractor'}], 'nodeType': 'USER', 'nodeId': '192.168.7.188'}}, {'ddn_id': '5a105e8b9d40e1329780d62ea2265d8a', 'ddn_name': 'test1', 'node_type': 'users', 'node_id': '192.168.7.166', 'node_attr': {'ip': '192.168.7.166', 'lastSeenTime': '1', 'edges': [{'idFrom': '192.168.7.166', 'idTo': 'youtube.com/12.3.4.52131'}], 'attributes': [{'attrName': 'user_access', 'attrType': 'ACCESS_GROUP', 'attrValue': 'executive'}], 'nodeType': 'USER', 'nodeId': '192.168.7.166'}}, {'ddn_id': 'ad0234829205b9033196ba818f7a872b', 'ddn_name': 'test2', 'node_type': 'users', 'node_id': '192.168.7.188', 'node_attr': {'ip': '192.168.7.188', 'lastSeenTime': '1', 'edges': [{'idFrom': '192.168.7.188', 'idTo': 'youtube.com/12.3.4.52131'}], 'attributes': [{'attrName': 'user_access', 'attrType': 'ACCESS_GROUP', 'attrValue': 'contractor'}], 'nodeType': 'USER', 'nodeId': '192.168.7.188'}}, {'ddn_id': 'ad0234829205b9033196ba818f7a872b', 'ddn_name': 'test2', 'node_type': 'users', 'node_id': '192.168.7.166', 'node_attr': {'ip': '192.168.7.166', 'lastSeenTime': '1', 'edges': [{'idFrom': '192.168.7.166', 'idTo': 'youtube.com/12.3.4.52131'}], 'attributes': [{'attrName': 'user_access', 'attrType': 'ACCESS_GROUP', 'attrValue': 'executive'}], 'nodeType': 'USER', 'nodeId': '192.168.7.166'}}, {'ddn_id': '5a105e8b9d40e1329780d62ea2265d8a', 'ddn_name': 'test1', 'node_type': 'applications', 'node_id': 'youtube.com/12.3.4.52131', 'node_attr': {'uri': 'youtube.com', 'appName': 'youtube.com', 'userAgent': 'Mozilla/5.0 (Windows NT 6.1; rv:1.9) Gecko/20100101 Firefox/4.0', 'ip': '12.3.4.5', 'port': 2131, 'host': 'youtube', 'nodeId': 'youtube.com/12.3.4.52131', 'attributes': [{'attrName': 'application_access', 'attrType': 'ACCESS_GROUP', 'attrValue': 'executive'}], 'inEdges': [{'idFrom': '192.168.7.188', 'idTo': 'youtube.com/12.3.4.52131'}, {'idFrom': '192.168.7.166', 'idTo': 'youtube.com/12.3.4.52131'}], 'outEdges': [{'idFrom': 'youtube.com/12.3.4.52131', 'idTo': '192.168.7.110:8080/helios/data/store/'}], 'nodeType': 'APPLICAITON'}}, {'ddn_id': 'ad0234829205b9033196ba818f7a872b', 'ddn_name': 'test2', 'node_type': 'applications', 'node_id': 'youtube.com/12.3.4.52131', 'node_attr': {'uri': 'youtube.com', 'appName': 'youtube.com', 'userAgent': 'Mozilla/5.0 (Windows NT 6.1; rv:1.9) Gecko/20100101 Firefox/4.0', 'ip': '12.3.4.5', 'port': 2131, 'host': 'youtube', 'nodeId': 'youtube.com/12.3.4.52131', 'attributes': [{'attrName': 'application_access', 'attrType': 'ACCESS_GROUP', 'attrValue': 'executive'}], 'inEdges': [{'idFrom': '192.168.7.188', 'idTo': 'youtube.com/12.3.4.52131'}, {'idFrom': '192.168.7.166', 'idTo': 'youtube.com/12.3.4.52131'}], 'outEdges': [{'idFrom': 'youtube.com/12.3.4.52131', 'idTo': '192.168.7.110:8080/helios/data/store/'}], 'nodeType': 'APPLICAITON'}}, {'ddn_id': '5a105e8b9d40e1329780d62ea2265d8a', 'ddn_name': 'test1', 'node_type': 'datastores', 'node_id': '192.168.7.110:8080/helios/data/store/', 'node_attr': {'nodeType': 'FILE', 'nodeId': '192.168.7.110:8080/helios/data/store/', 'tfName': \"Yuan's diary\", 'storageType': 'NFS', 'tfLoc': '192.168.7.110:8080/helios/data/store/', 'storageInfo': {'ip': '3.4.5.6', 'port': 1234, 'fsName': 'nfs', 'fileName': \"Yuan's diary\", 'fieldName': ['SOCIAL_SECURITY_NUMBER', 'FULL_NAME'], 'storageType': 'NFS', 'timestamp': 1234.0, 'attributes': [{'attrName': 'application_access', 'attrType': 'ACCESS_GROUP', 'attrValue': 'executive'}]}, 'edges': [{'idFrom': '12.3.4.5', 'idTo': '3.4.5.6'}]}}, {'ddn_id': 'ad0234829205b9033196ba818f7a872b', 'ddn_name': 'test2', 'node_type': 'datastores', 'node_id': '192.168.7.110:8080/helios/data/store/', 'node_attr': {'nodeType': 'FILE', 'nodeId': '192.168.7.110:8080/helios/data/store/', 'tfName': \"Yuan's diary\", 'storageType': 'NFS', 'tfLoc': '192.168.7.110:8080/helios/data/store/', 'storageInfo': {'ip': '3.4.5.6', 'port': 1234, 'fsName': 'nfs', 'fileName': \"Yuan's diary\", 'fieldName': ['SOCIAL_SECURITY_NUMBER', 'FULL_NAME'], 'storageType': 'NFS', 'timestamp': 1234.0, 'attributes': [{'attrName': 'application_access', 'attrType': 'ACCESS_GROUP', 'attrValue': 'executive'}]}, 'edges': [{'idFrom': '12.3.4.5', 'idTo': '3.4.5.6'}]}}]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "def __get_node_df(ddn_raw, node_type, node_id_tag):\n",
    "    \"\"\"\n",
    "    input ddn raw dict list from ddn pb, node type we deal with(can be applications, users or datastores)\n",
    "    \"\"\"\n",
    "    nodes_raw = [{'ddn_id': ddn['ddnId'], 'ddn_name': ddn['ddnName'], 'nodes': ddn[node_type]} for ddn in ddn_raw]\n",
    "    nodes_df = pd.DataFrame(nodes_raw)\n",
    "    #assign node_type\n",
    "    nodes_df['node_type'] = node_type\n",
    "    nodes_df = pandas_explode(nodes_df, \"nodes\")\n",
    "    nodes_df = nodes_df.rename(index=str, columns={\"nodes\": \"node\"})\n",
    "    #extract node_id from node column\n",
    "    nodes_df['node_id'] = nodes_df['node'].apply(lambda x: x[node_id_tag] )\n",
    "    #extract node_attr from node column\n",
    "    nodes_df['node_attr'] = nodes_df['node'].apply(lambda x: x)\n",
    "    #drop the original node column\n",
    "    nodes_df = nodes_df.drop(columns=['node'])\n",
    "    return nodes_df\n",
    "\n",
    "def _ddn_pb_to_nodes_df():\n",
    "    with open(\"data/ddn_test.json\") as f:\n",
    "        #ddn_raw = f.read()\n",
    "        ddn_raw = ast.literal_eval(f.read())\n",
    "    \n",
    "    usr_nodes_df = __get_node_df(ddn_raw, 'users', 'ip')\n",
    "    app_nodes_df = __get_node_df(ddn_raw, 'applications', 'nodeId')\n",
    "    dat_nodes_df = __get_node_df(ddn_raw, 'datastores', 'nodeId')\n",
    "\n",
    "    nodes_df = pd.concat([usr_nodes_df, app_nodes_df, dat_nodes_df], axis=0, sort=False)\n",
    "\n",
    "    #return usr_nodes_df\n",
    "    #return app_nodes_df\n",
    "    #return dat_nodes_df\n",
    "    return nodes_df\n",
    "\n",
    "test_node_df = _ddn_pb_to_nodes_df()\n",
    "res = test_node_df.to_dict('records')\n",
    "print(res)\n",
    "print(type(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'from_ddn_id': '5a105e8b9d40e1329780d62ea2265d8a', 'to_ddn_id': '5a105e8b9d40e1329780d62ea2265d8a', 'edges': [{'idFrom': '192.168.7.188', 'idTo': 'youtube.com/12.3.4.52131'}, {'idFrom': '192.168.7.166', 'idTo': 'youtube.com/12.3.4.52131'}]}, {'from_ddn_id': 'ad0234829205b9033196ba818f7a872b', 'to_ddn_id': 'ad0234829205b9033196ba818f7a872b', 'edges': [{'idFrom': '192.168.7.188', 'idTo': 'youtube.com/12.3.4.52131'}, {'idFrom': '192.168.7.166', 'idTo': 'youtube.com/12.3.4.52131'}]}, {'from_ddn_id': '5a105e8b9d40e1329780d62ea2265d8a', 'to_ddn_id': '5a105e8b9d40e1329780d62ea2265d8a', 'edges': [{'idFrom': 'youtube.com/12.3.4.52131', 'idTo': '192.168.7.110:8080/helios/data/store/'}]}, {'from_ddn_id': 'ad0234829205b9033196ba818f7a872b', 'to_ddn_id': 'ad0234829205b9033196ba818f7a872b', 'edges': [{'idFrom': 'youtube.com/12.3.4.52131', 'idTo': '192.168.7.110:8080/helios/data/store/'}]}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_ddn_id</th>\n",
       "      <th>to_ddn_id</th>\n",
       "      <th>from_node_id</th>\n",
       "      <th>to_node_id</th>\n",
       "      <th>edge_attr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a105e8b9d40e1329780d62ea2265d8a</td>\n",
       "      <td>5a105e8b9d40e1329780d62ea2265d8a</td>\n",
       "      <td>192.168.7.188</td>\n",
       "      <td>youtube.com/12.3.4.52131</td>\n",
       "      <td>{'idFrom': '192.168.7.188', 'idTo': 'youtube.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a105e8b9d40e1329780d62ea2265d8a</td>\n",
       "      <td>5a105e8b9d40e1329780d62ea2265d8a</td>\n",
       "      <td>192.168.7.166</td>\n",
       "      <td>youtube.com/12.3.4.52131</td>\n",
       "      <td>{'idFrom': '192.168.7.166', 'idTo': 'youtube.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ad0234829205b9033196ba818f7a872b</td>\n",
       "      <td>ad0234829205b9033196ba818f7a872b</td>\n",
       "      <td>192.168.7.188</td>\n",
       "      <td>youtube.com/12.3.4.52131</td>\n",
       "      <td>{'idFrom': '192.168.7.188', 'idTo': 'youtube.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ad0234829205b9033196ba818f7a872b</td>\n",
       "      <td>ad0234829205b9033196ba818f7a872b</td>\n",
       "      <td>192.168.7.166</td>\n",
       "      <td>youtube.com/12.3.4.52131</td>\n",
       "      <td>{'idFrom': '192.168.7.166', 'idTo': 'youtube.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a105e8b9d40e1329780d62ea2265d8a</td>\n",
       "      <td>5a105e8b9d40e1329780d62ea2265d8a</td>\n",
       "      <td>youtube.com/12.3.4.52131</td>\n",
       "      <td>192.168.7.110:8080/helios/data/store/</td>\n",
       "      <td>{'idFrom': 'youtube.com/12.3.4.52131', 'idTo':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ad0234829205b9033196ba818f7a872b</td>\n",
       "      <td>ad0234829205b9033196ba818f7a872b</td>\n",
       "      <td>youtube.com/12.3.4.52131</td>\n",
       "      <td>192.168.7.110:8080/helios/data/store/</td>\n",
       "      <td>{'idFrom': 'youtube.com/12.3.4.52131', 'idTo':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        from_ddn_id                         to_ddn_id  \\\n",
       "0  5a105e8b9d40e1329780d62ea2265d8a  5a105e8b9d40e1329780d62ea2265d8a   \n",
       "1  5a105e8b9d40e1329780d62ea2265d8a  5a105e8b9d40e1329780d62ea2265d8a   \n",
       "2  ad0234829205b9033196ba818f7a872b  ad0234829205b9033196ba818f7a872b   \n",
       "3  ad0234829205b9033196ba818f7a872b  ad0234829205b9033196ba818f7a872b   \n",
       "4  5a105e8b9d40e1329780d62ea2265d8a  5a105e8b9d40e1329780d62ea2265d8a   \n",
       "5  ad0234829205b9033196ba818f7a872b  ad0234829205b9033196ba818f7a872b   \n",
       "\n",
       "               from_node_id                             to_node_id  \\\n",
       "0             192.168.7.188               youtube.com/12.3.4.52131   \n",
       "1             192.168.7.166               youtube.com/12.3.4.52131   \n",
       "2             192.168.7.188               youtube.com/12.3.4.52131   \n",
       "3             192.168.7.166               youtube.com/12.3.4.52131   \n",
       "4  youtube.com/12.3.4.52131  192.168.7.110:8080/helios/data/store/   \n",
       "5  youtube.com/12.3.4.52131  192.168.7.110:8080/helios/data/store/   \n",
       "\n",
       "                                           edge_attr  \n",
       "0  {'idFrom': '192.168.7.188', 'idTo': 'youtube.c...  \n",
       "1  {'idFrom': '192.168.7.166', 'idTo': 'youtube.c...  \n",
       "2  {'idFrom': '192.168.7.188', 'idTo': 'youtube.c...  \n",
       "3  {'idFrom': '192.168.7.166', 'idTo': 'youtube.c...  \n",
       "4  {'idFrom': 'youtube.com/12.3.4.52131', 'idTo':...  \n",
       "5  {'idFrom': 'youtube.com/12.3.4.52131', 'idTo':...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def __get_edge_df(ddn_raw):\n",
    "    \"\"\"\n",
    "    input ddn raw dict list from ddn pb, node type we deal with(can be applications, users or datastores)\n",
    "    \"\"\"\n",
    "    edges_raw = [{'from_ddn_id': ddn['ddnId'], 'to_ddn_id': ddn['ddnId'],\n",
    "                      'edges': reduce(lambda x, y: x+y, [node['inEdges'] for node in ddn['applications']])} for ddn in ddn_raw]\n",
    "    \n",
    "    edges_raw.extend([{'from_ddn_id': ddn['ddnId'], 'to_ddn_id': ddn['ddnId'],\n",
    "                      'edges': reduce(lambda x, y: x+y, [node['outEdges'] for node in ddn['applications']])} for ddn in ddn_raw])\n",
    "    print(edges_raw)\n",
    "    edges_df = pd.DataFrame(edges_raw)\n",
    "    edges_df = pandas_explode(edges_df, \"edges\")\n",
    "    edges_df = edges_df.rename(index=str, columns={\"edges\": \"edge\"})\n",
    "    \n",
    "    #extract from_node_id and to_node_id from edge column\n",
    "    edges_df['from_node_id'] = edges_df['edge'].apply(lambda x: x['idFrom'])\n",
    "    edges_df['to_node_id'] = edges_df['edge'].apply(lambda x: x['idTo'])\n",
    "    #extract edge_attr from edge column\n",
    "    edges_df['edge_attr'] = edges_df['edge'].apply(lambda x: x)\n",
    "    #drop the original edge column\n",
    "    edges_df = edges_df.drop(columns=['edge'])\n",
    "    return edges_df\n",
    "\n",
    "def _ddn_pb_to_edges_df():\n",
    "    with open(\"data/ddn_test.json\") as f:\n",
    "        #ddn_raw = f.read()\n",
    "        ddn_raw = ast.literal_eval(f.read())\n",
    "    #let's assume we can get edge information from applications\n",
    "    edges_df = __get_edge_df(ddn_raw)\n",
    "    return edges_df\n",
    "\n",
    "test_edge_df = _ddn_pb_to_edges_df()\n",
    "test_edge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### The end of this file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
