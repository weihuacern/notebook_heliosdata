{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import json\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from graphviz import Digraph\n",
    "from graphviz import Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BrologAnalyzer:\n",
    "\n",
    "    def __init__(self, directory, target):\n",
    "        self._bro_dir = directory\n",
    "        self._bro_target = target\n",
    "        \n",
    "    def _get_entries(self, fname):\n",
    "        with open(self._bro_dir + fname) as f:\n",
    "            entries = f.readlines()\n",
    "        entries = [x.strip() for x in entries]\n",
    "        #print(len(entries))\n",
    "        return entries\n",
    "    \n",
    "    def _get_other_topics(self):\n",
    "        fnames = [f for f in listdir(self._bro_dir) if isfile(join(self._bro_dir, f))]\n",
    "        fnames.remove(self._bro_target)\n",
    "        if self._bro_target == \"conn.log\":\n",
    "            try:\n",
    "                fnames.remove(\"tds.log\")\n",
    "            except:\n",
    "                pass\n",
    "        #print(fnames)\n",
    "        return fnames\n",
    "    \n",
    "    def _get_target_tscut(self, target_log_str, tscut):\n",
    "        res = []\n",
    "        tstarget = json.loads(target_log_str)['ts']\n",
    "        orig_h_target = json.loads(target_log_str)['id.orig_h']\n",
    "        orig_p_target = json.loads(target_log_str)['id.orig_p']\n",
    "        resp_h_target = json.loads(target_log_str)['id.resp_h']\n",
    "        resp_p_target = json.loads(target_log_str)['id.resp_p']\n",
    "        \n",
    "        #print(tstarget)\n",
    "        #print(orig_h_target, orig_p_target)\n",
    "        #print(resp_h_target, resp_p_target)\n",
    "\n",
    "        fnames = self._get_other_topics()\n",
    "        for fname in fnames:\n",
    "            entries = self._get_entries(fname)\n",
    "            #print(fname)\n",
    "            #print(len(entries))\n",
    "            for entry in entries:\n",
    "                try:\n",
    "                    entry_dict = json.loads(entry)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    tsentry = entry_dict['ts']\n",
    "                    orig_h_entry = json.loads(entry)['id.orig_h']\n",
    "                    orig_p_entry = json.loads(entry)['id.orig_p']\n",
    "                    resp_h_entry = json.loads(entry)['id.resp_h']\n",
    "                    resp_p_entry = json.loads(entry)['id.resp_p']\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                #if_related = (orig_h_entry==resp_h_target and orig_p_entry==resp_p_target) or (resp_h_entry==resp_h_target and resp_p_entry==resp_p_target)\n",
    "                diff = tsentry - tstarget\n",
    "                if diff > 0 and diff < tscut:\n",
    "                    #print(entry)\n",
    "                    res.append(entry)\n",
    "        return res\n",
    "    \n",
    "    def _get_graph(self, outdir, outfname, target_log_str, res_log_str_list):       \n",
    "        dot = Digraph(comment='test graph')\n",
    "        orig_h_target = json.loads(target_log_str)['id.orig_h']\n",
    "        orig_p_target = json.loads(target_log_str)['id.orig_p']\n",
    "        resp_h_target = json.loads(target_log_str)['id.resp_h']\n",
    "        resp_p_target = json.loads(target_log_str)['id.resp_p']\n",
    "        #print(type(orig_h_target))\n",
    "        #print(type(orig_p_target))\n",
    "        dot.node(orig_h_target, str(orig_h_target), color='red')\n",
    "        dot.node(resp_h_target, str(resp_h_target), color='red')\n",
    "        dot.edge(orig_h_target, resp_h_target, constraint='false', headlabel = str(orig_p_target), taillabel = str(resp_p_target), labelfontsize=\"8\", len=\"3.0\", color='red')\n",
    "        \n",
    "        for res_log_str in res_log_str_list:\n",
    "            orig_h_res = json.loads(res_log_str)['id.orig_h']\n",
    "            orig_p_res = json.loads(res_log_str)['id.orig_p']\n",
    "            resp_h_res = json.loads(res_log_str)['id.resp_h']\n",
    "            resp_p_res = json.loads(res_log_str)['id.resp_p']\n",
    "            dot.node(orig_h_res, str(orig_h_res))\n",
    "            dot.node(resp_h_res, str(resp_h_res))\n",
    "            dot.edge(orig_h_res, resp_h_res, constraint='false', headlabel = str(orig_p_res), taillabel = str(resp_p_res), labelfontsize=\"8\", len=\"3.0\", color='blue')\n",
    "        \n",
    "        try:\n",
    "            dot.render(outdir + '/' + outfname, view=False)  \n",
    "            return dot\n",
    "        except:\n",
    "            print(\"render failed!\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#myBrologAnalyzer = BrologAnalyzer(\"../data/brologs/03-28/\", \"tds_sqlbatch.log\")\n",
    "myBrologAnalyzer = BrologAnalyzer(\"../data/brologs/03-28/\", \"conn.log\")\n",
    "\n",
    "#myBrologAnalyzer = BrologAnalyzer(\"../data/brologs/03-22-13/\", \"tds_sqlbatch.log\")\n",
    "#targets = myBrologAnalyzer._get_entries(myBrologAnalyzer._bro_target)\n",
    "#myBrologAnalyzer._get_entries(\"conn.log\")\n",
    "\n",
    "#for thistarget in targets:\n",
    "#    if json.loads(thistarget)['id.resp_p'] == 1433:\n",
    "        #print(thistarget)\n",
    "#        test_res = myBrologAnalyzer._get_target_tscut(thistarget, 1)\n",
    "        \n",
    "#myBrologAnalyzer._get_other_topics()\n",
    "#03-22-13\n",
    "#test_target_log_str = '{\"ts\":1521699403.756506,\"uid\":\"C4Y1Xt1AqErW7gd1Kl\",\"id.orig_h\":\"192.168.3.61\",\"id.orig_p\":61617,\"id.resp_h\":\"172.16.1.58\",\"id.resp_p\":1433,\"sqlbatch\":\"\\\\u0016\\\\u0012\\\\u0002\\\\u00fc\\\\u0088u\\\\u0001select * from EXT_ORDER_NEW\\\\u000d\\\\u000aWhere UPDSTATUS IS NUL\"}'\n",
    "#03-28\n",
    "#test_target_log_str = '{\"ts\":1522298700.448996,\"uid\":\"CJt0DqsKHR4gQU03e\",\"id.orig_h\":\"172.16.3.106\",\"id.orig_p\":51300,\"id.resp_h\":\"172.16.3.104\",\"id.resp_p\":1433,\"sqlbatch\":\"\\\\u0016\\\\u0012\\\\u0002\\\\u0001SELECT TOP 1 * FROM [INTClient\"}'\n",
    "#test_target_log_str = '{\"ts\":1522298698.48293,\"uid\":\"CP32sg2ZDTgkC1V2c4\",\"id.orig_h\":\"172.16.3.106\",\"id.orig_p\":51705,\"id.resp_h\":\"172.16.3.123\",\"id.resp_p\":1433,\"proto\":\"tcp\",\"duration\":99.982921,\"orig_bytes\":1,\"resp_bytes\":0,\"conn_state\":\"SF\",\"missed_bytes\":0,\"history\":\"DadAFf\",\"orig_pkts\":10,\"orig_ip_bytes\":452,\"resp_pkts\":10,\"resp_ip_bytes\":452,\"tunnel_parents\":[]}'\n",
    "#test_res_log_str_list = myBrologAnalyzer._get_target_tscut(test_target_log_str, 1)\n",
    "#print(len(test_res_log_str_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#res_dot = myBrologAnalyzer._get_graph(\"graph_plots\", \"test_graph.gv\", test_target_log_str, test_res_log_str_list)\n",
    "#print(str(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_labels = set([9,10,12,19,26,42,55,523])\n",
    "#good_labels = set()\n",
    "def _gen_graph_batch(thisBrologAnalyzer, tscut, port_target):\n",
    "    i = 0\n",
    "    outdir = \"graph_tscut_\" + str(tscut)\n",
    "    raw_targets = thisBrologAnalyzer._get_entries(thisBrologAnalyzer._bro_target)\n",
    "    targets = [x for x in raw_targets if ('\"id.resp_p\":' + str(port_target)) in x]\n",
    "    print(len(targets))\n",
    "    for thistarget in targets:\n",
    "        i += 1\n",
    "        print(\"processing event \" + str(i) + \"...\")\n",
    "        if i in good_labels:\n",
    "            outfname = \"graph_\" + str(i) + \"_\" + str(port_target) + \".gv\"\n",
    "            thisres_list = thisBrologAnalyzer._get_target_tscut(thistarget, tscut)\n",
    "            thisBrologAnalyzer._get_graph(outdir, outfname, thistarget, thisres_list)\n",
    "            with open(outdir + '/' + outfname + '.txt', 'a') as the_file:\n",
    "                the_file.write(\"Tagert: \\n\")\n",
    "                the_file.write(thistarget)\n",
    "                the_file.write(\"\\n\")\n",
    "                the_file.write(\"\\n\")\n",
    "                the_file.write(\"Ohters: \\n\")\n",
    "                for x in thisres_list:\n",
    "                    the_file.write(x)\n",
    "                    the_file.write(\"\\n\")\n",
    "                the_file.close()\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "#_gen_graph_batch(myBrologAnalyzer, 1, 1433)\n",
    "#_gen_graph_batch(myBrologAnalyzer, 5, 1433)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _ddn_json_reformat_js(path, fname):\n",
    "    nodes_list = []\n",
    "    edges_list = []\n",
    "    with open(path + fname) as f:\n",
    "        data = json.load(f)\n",
    "        nodes = json.loads(data['nodes'])\n",
    "        nodes_list = []\n",
    "        #em... let's try to add some icons...\n",
    "        for n in nodes[\"iid\"].keys():\n",
    "            nodes_list.append({\"name\": nodes[\"node_id\"][n], \"group\": nodes[\"type\"][n]})\n",
    "        \n",
    "        #\"iid\"\n",
    "        #nodes[\"iid\"]\n",
    "        inv_node_iid_map = {v: k for k, v in nodes[\"iid\"].items()}\n",
    "        #print(inv_node_iid_map)\n",
    "        \n",
    "        edges = json.loads(data['edges'])\n",
    "        for e in edges[\"ddn_id\"].keys():\n",
    "            thislabel = \"_\".join([edges[\"proto\"][e], edges[\"port\"][e], str(edges[\"total_bytes\"][e])])\n",
    "            #print(inv_node_id_map[edges[\"iid_from\"][e]])\n",
    "            #print(edges[\"iid_to\"][e])\n",
    "            iid_from = edges[\"iid_from\"][e]\n",
    "            iid_to = edges[\"iid_to\"][e]\n",
    "            if iid_from in inv_node_iid_map.keys() and iid_to in inv_node_iid_map.keys():\n",
    "                #print(iid_from, iid_to)\n",
    "                edges_list.append({\"source\": int(inv_node_iid_map[iid_from]), \"target\": int(inv_node_iid_map[iid_to]), \"label\": thislabel})\n",
    "    #return nodes_list\n",
    "    #return edges_list\n",
    "    ddn_d3_res = {\"nodes\": nodes_list, \"links\": edges_list}\n",
    "    \n",
    "    with open(\"../d3js/ddn/\" + \"d3js_\" + fname, 'w') as fp:\n",
    "        json.dump(ddn_d3_res, fp)\n",
    "    return ddn_d3_res\n",
    "\n",
    "ddn_dict_d3js = _ddn_json_reformat_js(\"../data/ddn/\", \"ddn_hr.json\")\n",
    "ddn_dict_d3js = _ddn_json_reformat_js(\"../data/ddn/\", \"ddn_pii.json\")\n",
    "#print(type(ddn_dict_d3js))\n",
    "#print(ddn_dict_d3js)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### The end of this file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
